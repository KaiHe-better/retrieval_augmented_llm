2023-11-29 20:34:07,951 **************** Configuration **************** 
2023-11-29 20:34:07,952 ID: 0
2023-11-29 20:34:07,952 config: llama2-7b_USMLE.yaml
2023-11-29 20:34:07,952 gpu: 5,6,7
2023-11-29 20:34:07,952 seed: 42
2023-11-29 20:34:07,952 num_workers: 16
2023-11-29 20:34:07,952 if_RA: False
2023-11-29 20:34:07,952 LLM: llama2-7b
2023-11-29 20:34:07,952 triever: dragon+
2023-11-29 20:34:07,952 dataset: USMLE
2023-11-29 20:34:07,952 prompt_file: prompts/USMLE.json
2023-11-29 20:34:07,952 retrieval_raw_data_dir: datasets/USMLE/textbooks/en
2023-11-29 20:34:07,952 retrieval_processed_file_dir: datasets/USMLE/process_retrieval_corpus/
2023-11-29 20:34:07,952 chunk_size: 512
2023-11-29 20:34:07,952 chunk_overlap: 20
2023-11-29 20:34:07,952 similarity_threshold: 0.7
2023-11-29 20:34:07,952 multi_query: False
2023-11-29 20:34:07,952 max_document_num: 9
2023-11-29 20:34:07,952 retri_batch_size: 512
2023-11-29 20:34:07,952 batch_size: 1
2023-11-29 20:34:07,952 demonstration: True
2023-11-29 20:34:07,952 demons_cnt: 1
2023-11-29 20:34:07,952 temperature: 0
2023-11-29 20:34:07,952 top_p: 0
2023-11-29 20:34:07,952 max_new_tokens: 2
2023-11-29 20:34:07,952 max_length: 2048
2023-11-29 20:34:07,952 device: cuda
2023-11-29 20:34:07,952 dir_path: ./results/output/gpu_5_6_7_config_llama2-7b_USMLE.yaml_demonstration_true_demons_cnt_1
2023-11-29 20:34:07,952 print_logger: <Logger print (DEBUG)>
2023-11-29 20:34:07,952 result_logger: <Logger result (DEBUG)>
2023-11-29 20:34:07,952 **************** Configuration **************** 


2023-11-29 20:34:07,952 Loading ../LLM_models/llama2/Llama-2-7b-chat-hf in torch.float16...
2023-11-29 20:34:41,200 Finish loading in 33.25 sec.
2023-11-29 20:34:41,255 Loading data ...
2023-11-29 20:34:41,291 prompt_format: general-demonstration-prompt 

2023-11-29 20:34:41,291 Start training... 
 
2023-11-29 20:34:41,835 process num: 0
